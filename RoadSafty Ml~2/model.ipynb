{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\aliar\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\aliar\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: shap in c:\\users\\aliar\\anaconda3\\lib\\site-packages (0.47.1)\n",
      "Collecting scikit-learn==1.6.1\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from scikit-learn==1.6.1) (3.5.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from shap) (4.66.5)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from shap) (4.11.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from numba>=0.54->shap) (0.43.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aliar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 882.6 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.8/11.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 1.3 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 1.3 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 1.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.8/11.1 MB 1.0 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.1/11.1 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.1 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.1 MB 1.0 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.4/11.1 MB 1.0 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.6/11.1 MB 932.2 kB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 927.0 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 946.4 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.4/11.1 MB 936.5 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.4/11.1 MB 936.5 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.7/11.1 MB 904.9 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 3.7/11.1 MB 904.9 kB/s eta 0:00:09\n",
      "   -------------- ------------------------- 3.9/11.1 MB 910.4 kB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.2/11.1 MB 935.6 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.5/11.1 MB 941.9 kB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 957.1 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 958.7 kB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 958.7 kB/s eta 0:00:07\n",
      "   ------------------ --------------------- 5.2/11.1 MB 943.1 kB/s eta 0:00:07\n",
      "   ------------------- -------------------- 5.5/11.1 MB 939.9 kB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.5/11.1 MB 939.9 kB/s eta 0:00:06\n",
      "   -------------------- ------------------- 5.8/11.1 MB 927.1 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.0/11.1 MB 927.3 kB/s eta 0:00:06\n",
      "   --------------------- ------------------ 6.0/11.1 MB 927.3 kB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 925.3 kB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 6.6/11.1 MB 927.8 kB/s eta 0:00:05\n",
      "   ------------------------ --------------- 6.8/11.1 MB 934.1 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.1/11.1 MB 938.0 kB/s eta 0:00:05\n",
      "   ------------------------- -------------- 7.1/11.1 MB 938.0 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.3/11.1 MB 934.0 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 7.3/11.1 MB 934.0 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 7.6/11.1 MB 919.3 kB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.6/11.1 MB 919.3 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 900.9 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 906.9 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 8.4/11.1 MB 904.5 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 8.4/11.1 MB 904.5 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 8.7/11.1 MB 903.8 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.1 MB 903.8 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.1 MB 903.8 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.9/11.1 MB 877.4 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 8.9/11.1 MB 877.4 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.2/11.1 MB 866.9 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 9.4/11.1 MB 859.7 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.4/11.1 MB 859.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.7/11.1 MB 861.6 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.0/11.1 MB 866.9 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.2/11.1 MB 866.2 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.2/11.1 MB 866.2 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.5/11.1 MB 871.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 872.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.1 MB 875.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 874.5 kB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.1\n",
      "    Uninstalling scikit-learn-1.5.1:\n",
      "      Successfully uninstalled scikit-learn-1.5.1\n",
      "Successfully installed scikit-learn-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost lightgbm shap scikit-learn==1.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded successfully.\n",
      "Shape: (5000, 10)\n",
      "\n",
      "=== Data Exploration ===\n",
      "\n",
      "Basic info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Location                       5000 non-null   object \n",
      " 1   Time                           5000 non-null   object \n",
      " 2   Lighting                       5000 non-null   object \n",
      " 3   Traffic_Density                5000 non-null   float64\n",
      " 4   Crime_Rate                     5000 non-null   float64\n",
      " 5   Police_Presence                5000 non-null   int64  \n",
      " 6   Public_Transport_Availability  5000 non-null   int64  \n",
      " 7   CCTV_Presence                  5000 non-null   int64  \n",
      " 8   Population_Density             5000 non-null   float64\n",
      " 9   Safe_Road                      5000 non-null   int64  \n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 390.8+ KB\n",
      "None\n",
      "\n",
      "First 5 rows:\n",
      "               Location   Time     Lighting  Traffic_Density  Crime_Rate  \\\n",
      "0              Alleyway  19:52  No lighting             0.30        0.65   \n",
      "1           Market Area  18:21  No lighting             0.35        0.32   \n",
      "2   Commercial District  04:35   Poorly-lit             0.04        0.56   \n",
      "3  Public Transport Hub  20:13  No lighting             0.04        0.39   \n",
      "4              Alleyway  02:44  No lighting             0.17        0.76   \n",
      "\n",
      "   Police_Presence  Public_Transport_Availability  CCTV_Presence  \\\n",
      "0                1                              0              0   \n",
      "1                0                              0              0   \n",
      "2                0                              0              1   \n",
      "3                0                              1              0   \n",
      "4                0                              0              0   \n",
      "\n",
      "   Population_Density  Safe_Road  \n",
      "0                0.15          0  \n",
      "1                0.83          0  \n",
      "2                0.76          0  \n",
      "3                0.83          0  \n",
      "4                0.29          0  \n",
      "\n",
      "Target distribution:\n",
      "Safe_Road\n",
      "0    0.635\n",
      "1    0.365\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values per column:\n",
      "Location                         0\n",
      "Time                             0\n",
      "Lighting                         0\n",
      "Traffic_Density                  0\n",
      "Crime_Rate                       0\n",
      "Police_Presence                  0\n",
      "Public_Transport_Availability    0\n",
      "CCTV_Presence                    0\n",
      "Population_Density               0\n",
      "Safe_Road                        0\n",
      "dtype: int64\n",
      "\n",
      "Descriptive statistics:\n",
      "       Traffic_Density   Crime_Rate  Police_Presence  \\\n",
      "count      5000.000000  5000.000000       5000.00000   \n",
      "mean          0.251944     0.470694          0.53360   \n",
      "std           0.193889     0.196161          0.49892   \n",
      "min           0.000000     0.050000          0.00000   \n",
      "25%           0.090000     0.320000          0.00000   \n",
      "50%           0.210000     0.450000          1.00000   \n",
      "75%           0.370000     0.610000          1.00000   \n",
      "max           0.960000     0.950000          1.00000   \n",
      "\n",
      "       Public_Transport_Availability  CCTV_Presence  Population_Density  \\\n",
      "count                    5000.000000    5000.000000         5000.000000   \n",
      "mean                        0.440600       0.416800            0.476348   \n",
      "std                         0.496509       0.493078            0.257676   \n",
      "min                         0.000000       0.000000            0.100000   \n",
      "25%                         0.000000       0.000000            0.230000   \n",
      "50%                         0.000000       0.000000            0.470000   \n",
      "75%                         1.000000       1.000000            0.740000   \n",
      "max                         1.000000       1.000000            0.900000   \n",
      "\n",
      "         Safe_Road  \n",
      "count  5000.000000  \n",
      "mean      0.365000  \n",
      "std       0.481478  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       0.000000  \n",
      "75%       1.000000  \n",
      "max       1.000000  \n",
      "\n",
      "Starting feature engineering...\n",
      "\n",
      "Starting preprocessing...\n",
      "Feature engineering completed.\n",
      "Preprocessing completed.\n",
      "\n",
      "Feature types after preprocessing:\n",
      "Location                           int32\n",
      "Lighting                           int32\n",
      "Traffic_Density                  float64\n",
      "Crime_Rate                       float64\n",
      "Police_Presence                    int64\n",
      "Public_Transport_Availability      int64\n",
      "CCTV_Presence                      int64\n",
      "Population_Density               float64\n",
      "Hour                               int64\n",
      "Is_Late_Night                      int64\n",
      "Is_Evening                         int64\n",
      "Lighting_Police                    int64\n",
      "Crime_Population                 float64\n",
      "dtype: object\n",
      "\n",
      "Splitting dataset into train and test sets...\n",
      "Train shape: (4000, 13), Test shape: (1000, 13)\n",
      "Train-Test split completed.\n",
      "\n",
      "Applying SMOTE to balance class distribution...\n",
      "Class distribution after SMOTE:\n",
      "Safe_Road\n",
      "0    2540\n",
      "1    2540\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aliar\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as final_model.pkl.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ") \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import joblib\n",
    "import shap\n",
    "from scipy.stats import uniform, randint\n",
    "from datetime import datetime\n",
    "\n",
    "# Load Dataset with enhanced error handling\n",
    "print(\"Loading dataset...\")\n",
    "try:\n",
    "    data = pd.read_csv(\"women_night_safety_dataset.csv\")\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(f\"Shape: {data.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Enhanced data exploration\n",
    "def explore_data(df):\n",
    "    print(\"\\n=== Data Exploration ===\")\n",
    "    print(\"\\nBasic info:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nTarget distribution:\")\n",
    "    print(df[\"Safe_Road\"].value_counts(normalize=True))\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(df.isna().sum())\n",
    "    print(\"\\nDescriptive statistics:\")\n",
    "    print(df.describe())\n",
    "\n",
    "explore_data(data)\n",
    "\n",
    "# Feature Engineering\n",
    "print(\"\\nStarting feature engineering...\")\n",
    "def extract_time_features(df):\n",
    "    # Convert time to datetime and extract features\n",
    "    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M').dt.time\n",
    "    df['Hour'] = df['Time'].apply(lambda x: x.hour)\n",
    "    df['Is_Late_Night'] = df['Hour'].apply(lambda x: 1 if x >= 23 or x <= 4 else 0)\n",
    "    df['Is_Evening'] = df['Hour'].apply(lambda x: 1 if 18 <= x <= 22 else 0)\n",
    "    return df\n",
    "\n",
    "data = extract_time_features(data)\n",
    "\n",
    "# Preprocessing\n",
    "print(\"\\nStarting preprocessing...\")\n",
    "\n",
    "# First encode categorical variables before creating interaction terms\n",
    "categorical_cols = [\"Location\", \"Lighting\"]\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    if col in data.columns:\n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Now create interaction features with encoded values\n",
    "data['Lighting_Police'] = data['Lighting'] * data['Police_Presence']\n",
    "data['Crime_Population'] = data['Crime_Rate'] * data['Population_Density']\n",
    "print(\"Feature engineering completed.\")\n",
    "\n",
    "# Handle missing values if any\n",
    "if data.isna().sum().any():\n",
    "    print(\"Handling missing values...\")\n",
    "    # Numerical columns - fill with median\n",
    "    num_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    num_cols = [col for col in num_cols if col not in [\"Safe_Road\", \"Hour\", \"Is_Late_Night\", \"Is_Evening\"]]\n",
    "    if len(num_cols) > 0:\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        data[num_cols] = num_imputer.fit_transform(data[num_cols])\n",
    "    \n",
    "    # Categorical columns - fill with most frequent\n",
    "    cat_cols = data.select_dtypes(include=['object']).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        data[cat_cols] = cat_imputer.fit_transform(data[cat_cols])\n",
    "\n",
    "print(\"Preprocessing completed.\")\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.drop([\"Safe_Road\", \"Time\"], axis=1)  # Dropping original Time column\n",
    "y = data[\"Safe_Road\"]\n",
    "\n",
    "# Ensure all features are numeric\n",
    "print(\"\\nFeature types after preprocessing:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "# Train-Test Split\n",
    "print(\"\\nSplitting dataset into train and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "print(\"Train-Test split completed.\")\n",
    "\n",
    "# Apply SMOTE to balance classes in training set\n",
    "print(\"\\nApplying SMOTE to balance class distribution...\")\n",
    "try:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    print(\"Class distribution after SMOTE:\")\n",
    "    print(pd.Series(y_train_resampled).value_counts())\n",
    "except Exception as e:\n",
    "    print(f\"Error applying SMOTE: {e}\")\n",
    "    print(\"Checking for non-numeric values in features...\")\n",
    "    print(X_train.dtypes)\n",
    "    # Convert any remaining object columns to numeric\n",
    "    for col in X_train.select_dtypes(include=['object']).columns:\n",
    "        X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    "        X_test[col] = pd.to_numeric(X_test[col], errors='coerce')\n",
    "    # Try SMOTE again\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    print(\"Class distribution after SMOTE (after conversion):\")\n",
    "    print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "# Train model\n",
    "print(\"\\nTraining model...\")\n",
    "model = HistGradientBoostingClassifier(random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"final_model.pkl\")\n",
    "print(\"Model saved as final_model.pkl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
